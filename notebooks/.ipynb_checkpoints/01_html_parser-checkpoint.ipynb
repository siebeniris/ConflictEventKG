{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "ea753be8-eb7c-488d-a580-98e03590b840",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import re\n",
    "import random\n",
    "from collections import defaultdict\n",
    "from itertools import chain\n",
    "import pandas as pd\n",
    "import codecs\n",
    "import json\n",
    "import os\n",
    "import lxml.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "afc41a59-9ef1-49b2-b8d2-54936b57649a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir= \"../data/wikipedia/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf785f6-c55f-47c8-ab6d-f164ff085c61",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "for file in os.listdir(data_dir):\n",
    "    if file.endswith(\".html\"):\n",
    "        date=file.split(\"/\")[-1].replace(\".html\", \"\")\n",
    "        date= date.replace(\"_February_\", \"-02-\").replace(\"_March_\", \"-03-\")\n",
    "        filepath = os.path.join(data_dir, file)\n",
    "        print(date)\n",
    "        with codecs.open(filepath, \"r\") as file:\n",
    "            data = file.read()\n",
    "        \n",
    "        entities_dict, news_dict, event_dict =parse_one_page_update(data, date)\n",
    "        \n",
    "        with open(f\"../data/output/news_dict_{date}.json\", \"w\") as file:\n",
    "            json.dump(news_dict, file)\n",
    "        \n",
    "        with open(f\"../data/output/entities_dict_{date}.json\", \"w\") as file:\n",
    "            json.dump(entities_dict, file)\n",
    "        \n",
    "        with open(f\"../data/output/events_dict_{date}.json\", \"w\") as file:\n",
    "            json.dump(event_dict, file)\n",
    "        \n",
    "        print(event_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a98b94-ba2e-4654-8fd9-0be8273cb5a9",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "with codecs.open(\"../data/wikipedia/2022_February_25.html\", \"r\") as file:\n",
    "    data = file.read()\n",
    "entities_dict, news_dict, event_dict =parse_one_page_update(data, \"2022-02-25\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0efdde46-1d65-4c37-9886-00ec937d4423",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lxml.cssselect import CSSSelector\n",
    "from lxml import etree\n",
    "from scrapy.selector import Selector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "cc63bb45-aafe-4e44-9433-66828b99d0eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# https://upg-dh.newtfire.org/explainXPath.html\n",
    "\n",
    "def parse_one_page_update(data, date):\n",
    "    keywords = [\"Russo\", \"Russia\", \"Ukrain\"]\n",
    "    entities_dict=dict()\n",
    "    news_dict= defaultdict(list)\n",
    "    event_dict=defaultdict(dict)\n",
    "    event_id = 0\n",
    "    \n",
    "    sl = Selector(text=data).xpath('//div[@class=\"current-events-content description\"]')\n",
    "    cats = sl.xpath(\"//b//text()\").getall()\n",
    "    # direct children from  div. \n",
    "    uls = sl.xpath(\"./ul\")\n",
    "    print(cats)\n",
    "    print(uls)\n",
    "    print(len(cats), len(uls))\n",
    "    if date==\"2022-02-25\":\n",
    "        uls.pop(5)\n",
    "    assert len(cats)==len(uls)\n",
    "    \n",
    "    for cat, ul in zip(cats, uls):\n",
    "        print(\"category:\", cat) # category for the individual events.\n",
    "        lis = ul.xpath(\"./li\")\n",
    "        # texts = ul.xpath(\"./li/a\").getall()\n",
    "        texts = ul.xpath(\"./li\").getall()\n",
    "        print(\"leading events ->\", texts)\n",
    "        \n",
    "        idxes=[idx for idx, title in enumerate(texts) if any([x in title for x in keywords])]\n",
    "        print(lis)\n",
    "        \n",
    "        li_uls = [[li.xpath(\"./ul\") for li in lis][x] for x in idxes]\n",
    "        leading_events= [texts[x] for x in idxes]\n",
    "                              \n",
    "        if len(li_uls)>0:\n",
    "            for idx, el in enumerate(li_uls[0]):\n",
    "                leading_event= leading_events[idx]\n",
    "                leading_event= Selector(text=leading_event)\n",
    "                print(\"leading event:\", leading_event) # TODO get the entity.\n",
    "                leading_event_title = leading_event.css(\"a::attr(title)\").get()\n",
    "                leading_event_href= leading_event.css(\"a::attr(href)\").get()\n",
    "                if leading_event_title not in entities_dict:\n",
    "                    entities_dict[leading_event_title] = leading_event_href\n",
    "                \n",
    "                for el_li in el.css(\"li\"):\n",
    "                    entities = []\n",
    "                    news = [] # paper: link\n",
    "                    text_list = el_li.xpath(\"descendant::text()\").getall()\n",
    "                    \n",
    "                    # get direct events\n",
    "                    if \"\\n\" not in text_list:\n",
    "                        print(el_li)\n",
    "                        event_text = \"\".join(text_list)\n",
    "                        event_text = \"\".join(re.split(\"\\(|\\)|\\[|\\]\", event_text)[::2])\n",
    "                        print(event_text)\n",
    "                        \n",
    "                        ### check the links.\n",
    "                        for al in el_li.xpath(\"./a\"):\n",
    "                            if al.css(\"a::attr(title)\").get():\n",
    "                                title = al.css(\"a::attr(title)\").get()\n",
    "                                href = al.css(\"a::attr(href)\").get()\n",
    "                                entities.append(title)\n",
    "                                if title not in entities_dict:\n",
    "                                    entities_dict[title]=href\n",
    "                            else:\n",
    "                                href= al.css(\"a::attr(href)\").get()\n",
    "                                # text = al.css(\"a::text\").extract()\n",
    "                                news.append(href)\n",
    "                        print(\"entities\", entities)\n",
    "                        print(\"news\", news)\n",
    "                        print(\"leading event: \", leading_event)\n",
    "                        news_dict[event_id]=news\n",
    "                        event_dict[event_id]={\n",
    "                            \"cateogry\": cat,\n",
    "                            \"event_text\": event_text,\n",
    "                            \"main_event\": leading_event_title,\n",
    "                            \"date\":date, \n",
    "                            \"news\": news,\n",
    "                            \"entities\": entities\n",
    "                        }\n",
    "                        event_id +=1\n",
    "                        \n",
    "                    print(\"*\"*40)\n",
    "    return entities_dict, news_dict, event_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b49b1e25-5677-411a-ac4e-8788285fd932",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "388eb41f-5015-4535-a107-d03943a98193",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7f1344-1845-4d8b-b23e-28b7dbc80d30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "06500982-4360-42a0-863c-6194e1995aaa",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def parse_one_html(data, date):\n",
    "    soup = BeautifulSoup(data, \"html.parser\")\n",
    "    div = soup.find(\"div\", {\"class\":\"current-events-content description\"})\n",
    "    entities_dict = defaultdict(dict)\n",
    "    news = defaultdict(list)\n",
    "    event_dict= defaultdict(dict)\n",
    "    counter = 0 \n",
    "    category_ =\"\"\n",
    "    \n",
    "    for elem in div:\n",
    "\n",
    "        if elem.name==\"p\":\n",
    "            category=elem.get_text() \n",
    "            category_ = category.replace(\"\\n\", \"\")\n",
    "        if elem.name==\"ul\":\n",
    "            # for next_elem in elem.next_elements:\n",
    "            #     print(next_elem)\n",
    "            #     try:\n",
    "            #         for el in next_elem.find(\"li\"):\n",
    "            #             print(el.get_text())\n",
    "            #             print(\"====\")\n",
    "            #     except Exception:\n",
    "            #         print(next_elem)\n",
    "            \n",
    "                # if next_elem.name==\"li\":\n",
    "                #     event= next_elem.get_text()\n",
    "                #     print(event)\n",
    "                #     print(\"====\")\n",
    "            for el in elem.find(\"li\"):\n",
    "                events = el.get_text().split(\"\\n\")\n",
    "                \n",
    "                entities_ls = []\n",
    "                leading_event = events[0]\n",
    "                print(leading_event)\n",
    "                if any([x in leading_event for x in [\"Russo\", \"Ukrain\", \"Russia\"]]):\n",
    "                    for a in el.find_all(\"a\", href=True):\n",
    "                        href = a[\"href\"]\n",
    "                        try:\n",
    "                            title = a[\"title\"]\n",
    "                            entities_dict[title]={\"link\":href, \"category\":category_\n",
    "                                                 , \"leading\": leading_event}\n",
    "                            entities_ls.append(title)\n",
    "                        except Exception:\n",
    "                            if href.startswith(\"https:\"):\n",
    "                                news[category_].append({\n",
    "                                \"link\":href, \"leading\":leading_event\n",
    "                                })\n",
    "\n",
    "\n",
    "                    event_dict[counter]={\n",
    "                                    \"events\":events, \n",
    "                                    \"leading\":leading_event,\n",
    "                                    \"entities\": entities_ls, \n",
    "                                    \"date\":date,\n",
    "                                    \"category\":category_\n",
    "                                }\n",
    "                    counter+=1\n",
    "                    print(\"======\"*100)\n",
    "    return event_dict, entities_dict, news\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python-eve",
   "language": "python",
   "name": "eve"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
